---
title: "Week3_Manipulating_Data"
author: "Bangda Sun"
date: "October 24, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 1. Subsetting and sorting

#### Subsetting - quick review
```{r}
set.seed(13435)
# create data frame
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
# sampling
X <- X[sample(1:5), ]
X$var2[c(1, 3)] <- NA
X
X[, 1]
X[, "var1"]
X[1:2, "var2"]
```

#### Logicals ands and ors
```{r}
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 15), ]
```

#### Dealing with missing values
```{r}
# use which() command
X
X[which(X$var2 > 8), ]
```

#### Sorting
```{r}
sort(X$var1)
sort(X$var1, decreasing = TRUE)
# let NA as last position     
sort(X$var2, na.last = TRUE)
```

#### Ordering
```{r}
# order by var1
X[order(X$var1), ]
X[order(X$var1, X$var3), ]
```

#### Ordering with plyr package
```{r}
library(plyr)
# increasing order
arrange(X, var1)
# decreasing order
arrange(X, desc(var1))
```

#### Adding rows (rbind) and columns (cbind) 
```{r}
# method 1
X$var4 <- rnorm(5)
X
# method 2
Y <- cbind(X, rnorm(5))
Y
```

### 2. Summarizing data

#### Example data set
https://data.baltimorecity.gov/Community/Restaurants/k5ry-ef3g

```{r}
setwd("C://Users//Bangda//Dropbox//Get and Cleaning data in R//Week 3")
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "restaurants.csv", method = "wininet")
restData <- read.csv("restaurants.csv")
```

#### Look at a bit of the data
```{r}
head(restData, n = 3)
tail(restData, n = 3)
```

#### Make summary
```{r}
summary(restData)
```

#### Mpre in depth information
```{r}
str(restData)
```

#### Quantiles of quantitative variables
```{r}
quantile(restData$councilDistrict, na.rm = TRUE)
quantile(restData$councilDistrict, probs = c(.5, .75, .9))
```

#### Make table
```{r}
# see if NA exists
table(restData$zipCode, useNA = "ifany")
table(restData$councilDistrict, restData$zipCode)
```

#### Check for missing values
```{r}
sum(is.na(restData$councilDistrict))
# if exists NA
any(is.na(restData$councilDistrict))
# if every value satisfy something
all(restData$zipCode > 0)
```

#### Row and column sums
```{r}
# check if exists NA values
colSums(is.na(restData))
all(colSums(is.na(restData)) == 0)
```

#### Values with specific characteristic
```{r}
# find the number zipCode is "21212"
table(restData$zipCode %in% c("21212"))
# find the number of zipCode is "21212" and "21213"
table(restData$zipCode %in% c("21212", "21213"))
# display the terms satisfy the condition
restData[restData$zipCode %in% c("21212", "21213"), ]
```

#### Cross tabs
```{r}
# UC Berkeley admission data
data("UCBAdmissions")
DF <- as.data.frame(UCBAdmissions)
summary(DF)
# cross table
xt <- xtabs(Freq ~ Gender + Admit, data = DF)
xt
```

#### Flat tales
```{r}
warpbreaks$replicate <- rep(1:9, length = 54)
xt <- xtabs(breaks ~., data = warpbreaks)
xt
ftable(xt)
```

#### Size of data set
```{r}
fakeData <- rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData), units = "Mb")
```

### 3. Creating new variables

Sometimes we need to transform the data. Common variables to create: missingness indicators; "cutting up" quantitative variables; applying transforms

#### Example

```{r}
# getting the data from the web
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "restaurants2.csv", method = "wininet")
restData2 <- read.csv("restaurants2.csv")
```

#### Creating sequences
```{r}
s1 <- seq(1, 10, by = 2); s1
s2 <- seq(1, 10, length = 3); s2
x <- c(1, 3, 8, 25, 100); seq(along = x)
```

#### Subsetting variables
```{r}
# creating new variable
restData2$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData2$nearMe)
```

#### Creating binary variables
```{r}
# use ifelse() function
restData2$zipWrong <- ifelse(restData2$zipCode < 0, TRUE, FALSE)
table(restData2$zipWrong, restData2$zipCode < 0)
```

#### Creating categorical variables
```{r}
# use quantile() to create different groups of data to "cut" data
restData2$zipGroups <- cut(restData2$zipCode, breaks = quantile(restData2$zipCode))
table(restData2$zipGroups)
table(restData2$zipGroups, restData2$zipCode)
```

#### Easier cutting
```{r}
library(Hmisc)
restData2$zipGroups <- cut2(restData2$zipCode, g = 4)
table(restData2$zipGroups)
```

#### Creating factor variables
```{r}
restData2$zcf <- factor(restData2$zipCode)
restData2$zcf[1:10]
class(restData2$zcf)
```

#### Levels of factor variables
```{r}
yesno <- sample(c("yes", "no"), size = 10, replace = TRUE)
yesnofac <- factor(yesno, levels = c("yes", "no"))
relevel(yesnofac, ref = "yes")
as.numeric(yesnofac)
```

#### Cutting produces factor variables
```{r}
restData2$zipGroups <- cut2(restData2$zipCode, g = 4)
table(restData2$zipGroups)
```

#### Using the mutate function
```{r}
library(plyr)
restData3 <- mutate(restData2, zipGroups = cut2(zipCode, g = 4))
table(restData3$zipGroups)
```

#### Common transforms
```
abs(x)
sqrt(x)
ceiling(x)
floor(x)
round(x, digits = n)
signif(x, digits = n)
cos(x); sin(x)
log(x); log2(x); log10(x)
exp(x)
```

### 4. Rshaping data

The goal is tidy data: 1) each variable forms a column; 2) each observation forms a row; 3) each table stores data about one kind of observation.

#### Starting with reshaping
```{r}
library(reshape2)
head(mtcars)
```

#### Melting data frames
```{r}
# create a new variable denote the name or cars
mtcars$carname <- rownames(mtcars)
# melt data: set id and measure variables
carMelt <- melt(mtcars, id = c("carname", "gear", "cyl"), measure.vars = c("mpg", "hp"))
```

#### Casting data frames
```{r}
# reshape the dataframe: cyl break down by different variables
cylData <- dcast(carMelt, cyl ~ variable)
cylData
# use function to summarize data
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
```

#### Average values
```{r}
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray, sum)
```

#### Another way: split
```{r}
spIns <- split(InsectSprays$count, InsectSprays$spray)
spIns
sprCount <- lapply(spIns, sum)
sprCount
unlist(sprCount)
sapply(spIns, sum)
```

#### Another way - plyr package
```{r}
# summarize spray, use sum()
# ddply(InsectSprays, .(spray), summarize, sum = sum(count))
```

### Managing Data Frames with dplyr - Introduction

Including arrange, filter, select, mutate, rename, etc.

dply Verbs:
`select`: return a subset of columns of a data frame.
`filter`: extract a subset of rows from a data frame based on logical conditions.
`arrange`: reorder rows of a data frame.
`rename`: rename variables in a data frame.
`mutate`: add new variables/columns or transform existing variables.
`summarise/summarize`: generate summary statistics of different variables in the data frame.

The first argument is a data frame. The subsequent arguments describe what to do with it, and you can refer to columns in the data frame directly without using $ operator, just use the names. The result is a new data frame. Data frame must be properly formatted and annotated for this to all be useful.

### Managing Data frames with dplyr - Basic Tools
```{r}
library(dplyr)
options(width = 105)
# weather data in chicago
chicago <- readRDS("chicago.rds")
dim(chicago)
str(chicago)
# see the name of the variables
names(chicago)
# view the variable: city to dptp
head(select(chicago, city:dptp))
# without some variables
head(select(chicago, -(city:dptp)))
# find the index of the column
i <- match("city", names(chicago)); i
j <- match("dptp", names(chicago)); j
# subset data
#  we can refer to the variable directly
chi.f <- filter(chicago, pm25tmean2 > 30)
head(chi.f)
chi.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chi.f)
# reorder the data frame: arrange
chicago <- arrange(chicago, date)
head(chicago)
# descending order
chicago <- arrange(chicago, desc(date))
# rename() function
#  return error below...
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
# mutate() function
# create new variable
#  return error below...
chicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))
# group() function, spilt data
chicago <- mutate(chicago, tempcat = factor(1 * (tmpd > 80), labels = c("cold", "hot")))
hotcold <- group_by(chicago, tempcat)
hotcold
# summarize(hotcold, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2))
# chicago <- mutate(chicago, years = as.POSIXlt(date)$year + 1900)
# summarize(years, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2))
#
# chicago %>% mutate(month = as.POSIXlt(date)$mon + 1) %>% group_by(month) %>% summarize(pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2))
# %>% operator
```

Additional benefits: dplyr can work with other data frame "backends"; data.table for large fast tables; SQL interface for relational databases via the DBI package.

### Merging Data
Sometimes you'll load in more than one dataset into R and you'll want to be able to merge the datasets together. And usually what you'll want to do is match those datasets based on an ID.
```{r}
fileUrl1 <- "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1, destfile = "reviews.csv", method = "wininet")
download.file(fileUrl2, destfile = "solutions.csv", method = "wininet")
reviews <- read.csv("reviews.csv")
solutions <- read.csv("solutions.csv")
head(reviews, 2)
head(solutions, 2)
# solution_id is the id in solution
```

#### Merging data - merge()
Important parameters: x, y, by.x, by.y, all (default)
```{r}
names(reviews)
names(solutions)
mergedData <- merge(reviews, solutions, by.x = "solution_id", by.y = "id", all = TRUE)
head(mergedData)
# id is id in the reviews data frame
# merge all common columns
intersect(names(solutions), names(reviews))
# use join() in plyr package
df1 <- data.frame(id = sample(1:10), x = rnorm(10))
df2 <- data.frame(id = sample(1:10), y = rnorm(10))
arrange(join(df1, df2), id)
# join multiple data frames
df3 <- data.frame(id = sample(1:10), z = rnorm(10))
dfList <- list(df1, df2, df3)
join_all(dfList)
```













